### **AWS S3 Overview and Key Concepts**

**Amazon Simple Storage Service (Amazon S3)** is a scalable object storage service designed to store and retrieve any amount of data from anywhere, at any time. It provides high availability, durability, and security, and is widely used for storing files, backups, images, videos, and application data.

### **Core Components of S3**:

1. **Buckets**: 
   - A container for storing objects. Each bucket must have a globally unique name.
   - Objects are stored within buckets, and all S3 objects must belong to a bucket.

2. **Objects**: 
   - The actual data stored in S3, such as files, images, videos, etc. 
   - Each object is identified by a key (unique within a bucket), and the size of each object can be up to 5 TB.

3. **Bucket Settings**:
   - Control access to the bucket and its contents.
   - Examples: Versioning, permissions, lifecycle policies.

4. **ACL Settings**:
   - Access Control Lists (ACLs) define the permissions for individual objects and buckets.

5. **Versioning**:
   - Allows you to keep multiple versions of an object in the same bucket.
   - This helps in data recovery from unintended actions or application failures.

6. **Static Web Hosting**:
   - You can host a static website on S3 by configuring the bucket for static web hosting.
   
7. **Replication**:
   - Replication allows automatic copying of objects between S3 buckets, either within the same region or across different regions.

8. **Lifecycle Policies**:
   - Define rules for automatically managing your objects, such as moving them to different storage classes or deleting them after a specified time.

9. **AWS Transfer Family (SFTP)**:
   - Provides secure file transfer capabilities over SFTP, FTPS, and FTP to and from S3.

10. **AWS Storage Gateway**:
   - Enables hybrid cloud storage, allowing on-premises applications to seamlessly use cloud storage.

11. **AWS DataSync**:
   - Automates and accelerates moving data between on-premises storage and S3.

---

### **Creating an S3 Bucket and Uploading Objects**

1. **Create a Bucket**:
   - Go to the S3 Console and click "Create Bucket."
   - **Bucket Name**: `Aja-devops` (Must be globally unique)
   - **ACLs**: Disabled
   - **Versioning**: Disabled
   - **Bucket Settings**: Enable the default settings and click "Create Bucket."

2. **Upload Objects to S3**:
   - Select the bucket you created.
   - Click "Upload" and select the files or folders you want to upload.
   - Files of any type (images, code, documents, videos, etc.) can be uploaded.
   - Objects can be as large as 5 TB.

---

### **Permissions and Access Control**

1. **Bucket Settings**:
   - **Block Public Access**: Disable public access to ensure no one can access the bucket unless explicitly granted.
   
2. **Object Ownership**:
   - **Enable object ownership** to manage how objects in your bucket are owned.
   
3. **ACL Settings**:
   - **Make Object Public**: 
     - After uploading an object, you can make it public using the ACL settings by selecting "Make public using ACL."

---

### **Pre-Signed URLs for Temporary Object Access**

- A **pre-signed URL** grants temporary access to a specific S3 object without altering the bucketâ€™s ACLs or settings. It allows clients to access objects for a limited time (1 to 12 hours).
  - To generate a pre-signed URL:
    1. Select the object in S3.
    2. Go to "Actions" and choose "Share Pre-signed URL."
    3. Set the duration for access.

---

### **Bucket Versioning**

- **Versioning** allows you to keep multiple versions of an object, providing an easy way to recover from unintended deletions or changes.
  - To enable versioning: 
    1. Go to the bucket settings.
    2. Edit and enable **Versioning**.

- **Important**: Always ensure the **Show Versions** switch is off before deleting files, as versioned files can lead to additional management complexities.

---

### **Static Web Hosting on S3**

- S3 can host static websites (HTML, CSS, JavaScript files).
  - Steps to enable:
    1. Upload the website files to the S3 bucket.
    2. Enable static website hosting in the bucket properties.
    3. Set the appropriate **Bucket Policy** to allow public access:
       ```json
       {
           "Version": "2012-10-17",
           "Statement": [
               {
                   "Sid": "PublicReadGetObject",
                   "Effect": "Allow",
                   "Principal": "*",
                   "Action": ["s3:GetObject"],
                   "Resource": ["arn:aws:s3:::Bucket-Name/*"]
               }
           ]
       }
       ```
    4. Save the policy and use the provided URL to access your website.

---

### **S3 Replication**

- **Replication** enables automatic copying of objects across S3 buckets (within the same or different regions).
  - Steps:
    1. Select the bucket to configure replication.
    2. Go to the **Management** tab and click on **Replication**.
    3. Create a replication rule:
       - Select the source and destination buckets.
       - Create an IAM role for the replication process.
       - Save the rule, and objects will be copied automatically to the destination bucket.

---

### **S3 Lifecycle Rules**

- **Lifecycle Rules** help automate data management by transitioning objects to different storage classes or deleting them after a certain period.
  - **Transition**: Move objects between storage classes like S3 Standard, S3 Glacier, etc.
  - **Expiration**: Automatically delete objects after a set time.
  - **Noncurrent Version Expiration**: Expire previous versions of versioned objects.
  - **Abort Incomplete Multipart Uploads**: Abort multipart uploads that haven't completed within a specified time.

#### Example Scenarios:
1. **Move logs to S3 Standard-IA after 30 days**:
   - Prefix: `logs/`
   - Action: Transition to S3 Standard-IA after 30 days.

2. **Delete old backups older than 365 days**:
   - Prefix: `old-backups/`
   - Action: Expire objects older than 365 days.

3. **Move archive data to S3 Glacier after 180 days, delete after 365 days**:
   - Prefix: `archive/`
   - Action: Transition to S3 Glacier after 180 days, delete after 365 days.

By setting up these rules, you can optimize storage costs by automatically managing data over time.

---

### **S3 Storage Classes**

1. **S3 Standard**: For frequently accessed data.
2. **S3 Intelligent-Tiering**: For data with unpredictable access patterns.
3. **S3 Standard-IA**: For infrequently accessed data.
4. **S3 One Zone-IA**: For infrequent access data with lower resilience.
5. **S3 Glacier**: For archival data with retrieval times in hours.
6. **S3 Glacier Deep Archive**: For long-term archival with retrieval times in hours.
7. **S3 Reduced Redundancy Storage (RRS)**: Deprecated.

These storage classes help optimize cost based on the frequency of access and the importance of data resilience.